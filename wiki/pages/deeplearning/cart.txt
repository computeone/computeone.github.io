**CART算法**有两步：\\
\\
决策树生成和剪枝。\\
\\
决策树生成：递归地构建二叉决策树的过程，基于训练数据集生成决策树，生成的决策树要尽量大；\\
\\
自上而下从根开始建立节点，在每个节点处要选择一个最好的属性来分裂，使得子节点中的训练集尽量的纯。\\
\\
不同的算法使用不同的指标来定义"最好"：\\
\\
  * 分类问题，可以选择GINI，双化或有序双化；\\
  * 回归问题，可以使用最小二乘偏差（LSD）或最小绝对偏差（LAD）。\\
\\
决策树剪枝：用验证数据集对已生成的树进行剪枝并选择最优子树，这时损失函数最小作为剪枝的标准。\\
\\
\\
**一个具体的例子**

下面来看一个具体的例子。我们使用下图所示的数据集来作为示例，为了便于后面的叙述，我们将其再列出如下：\\
\\
{{:deeplearning:cart1.png?400|}}\\
\\
首先对数据集非类标号属性{是否有房，婚姻状况，年收入}分别计算它们的Gini系数增益，取Gini系数增益值最大的属性作为决策树的根节点属性。根节点的Gini系数 \\
\\
       Gini(是否拖欠贷款)=1−(310)2−(710)2=0.42
\\
当根据是否有房来进行划分时，Gini系数增益计算过程为\\
\\
{{:deeplearning:cart2.png?400|}}\\
\\
         Gini(左子节点)=1−(03)2−(33)2=0
         Gini(右子节点)=1−(37)2−(47)2=0.4898
         Δ{是否有房}=0.42−710×0.4898−310×0=0.077
\\
\\
若按婚姻状况属性来划分，属性婚姻状况有三个可能的取值{married，single，divorced}，分别计算划分后的
\\
  * {married} | {single,divorced}\\
  * {single} | {married,divorced}\\
  * {divorced} | {single,married}\\
的Gini系数增益。 \\
当分组为{married} | {single,divorced}时，Sl表示婚姻状况取值为married的分组，Sr表示婚姻状况取值为single或者divorced的分组 
\\
          Δ{婚姻状况}=0.42−410×0−610×[1−(36)2−(36)2]=0.12
\\
当分组为{single} | {married,divorced}时，\\
\\ 
         Δ{婚姻状况}=0.42−410×0.5−610×[1−(16)2−(56)2]=0.053
\\
当分组为{divorced} | {single,married}时， \\
\\
        Δ{婚姻状况}=0.42−210×0.5−810×[1−(28)2−(68)2]=0.02
\\

对比计算结果，根据婚姻状况属性来划分根节点时取Gini系数增益最大的分组作为划分结果，也就是{married} | {single,divorced}。
最后考虑年收入属性，我们发现它是一个连续的数值类型。我们在前面的文章里已经专门介绍过如何应对这种类型的数据划分了。对此还不是很清楚的朋友可以参考之前的文章，这里不再赘述。\\
\\
对于年收入属性为数值型属性，首先需要对数据按升序排序，然后从小到大依次用相邻值的中间值作为分隔将样本划分为两组。例如当面对年收入为60和70这两个值时，我们算得其中间值为65。倘若以中间值65作为分割点。Sl作为年收入小于65的样本，Sr表示年收入大于等于65的样本，于是则得Gini系数增益为 \\
\\
          Δ(年收入)=0.42−110×0−910×[1−(69)2−(39)2]=0.02
\\
其他值的计算同理可得，我们不再逐一给出计算过程，仅列出结果如下（最终我们取其中使得增益最大化的那个二分准则来作为构建二叉树的准则）：\\
{{:deeplearning:cart3.png?700|}}
\\
{{:deeplearning:cart4.png?400|}}